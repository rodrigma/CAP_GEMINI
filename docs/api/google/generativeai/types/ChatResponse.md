description: A chat response from the model.

<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="google.generativeai.types.ChatResponse" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__eq__"/>
<meta itemprop="property" content="reply"/>
<meta itemprop="property" content="to_dict"/>
<meta itemprop="property" content="top_k"/>
<meta itemprop="property" content="top_p"/>
</div>

# google.generativeai.types.ChatResponse

<!-- Insert buttons and diff -->

<table class="tfo-notebook-buttons tfo-api nocontent" align="left">
<td>
  <a target="_blank" href="https://github.com/google/generative-ai-python/blob/master/google/generativeai/types/discuss_types.py#L108-L202">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub
  </a>
</td>
</table>



A chat response from the model.

<!-- Placeholder for "Used in" -->

* Use `response.last` (settable) for easy access to the text of the last response.
    (`messages[-1]['content']`)
* Use `response.messages` to access the message history (including `.last`).
* Use `response.candidates` to access all the responses generated by the model.

Other attributes are just saved from the arguments to `genai.chat`, so you
can easily continue a conversation:

```
import google.generativeai as genai

genai.configure(api_key=os.environ['GOOGLE_API_KEY'])

response = genai.chat(messages=["Hello."])
print(response.last) #  'Hello! What can I help you with?'
response.reply("Can you tell me a joke?")
```

See `genai.chat` for more details.



<!-- Tabular view -->
 <table class="responsive fixed orange">
<colgroup><col width="214px"><col></colgroup>
<tr><th colspan="2"><h2 class="add-link">Attributes</h2></th></tr>

<tr>
<td>
`candidates`<a id="candidates"></a>
</td>
<td>
A list of candidate responses from the model.

The top candidate is appended to the `messages` field.

This list will contain a *maximum* of `candidate_count` candidates.
It may contain fewer (duplicates are dropped), it will contain at least one.

Note: The `temperature` field affects the variability of the responses. Low
temperatures will return few candidates. Setting `temperature=0` is deterministic,
so it will only ever return one candidate.
</td>
</tr><tr>
<td>
`filters`<a id="filters"></a>
</td>
<td>
This indicates which `types.SafetyCategory`(s) blocked a
candidate from this response, the lowest <a href="../../../google/generativeai/types/HarmProbability.md"><code>types.HarmProbability</code></a>
that triggered a block, and the `types.HarmThreshold` setting for that category.
This indicates the smallest change to the `types.SafetySettings` that would be
necessary to unblock at least 1 response.

The blocking is configured by the `types.SafetySettings` in the request (or the
default `types.SafetySettings` of the API).
</td>
</tr><tr>
<td>
`messages`<a id="messages"></a>
</td>
<td>
A snapshot of the conversation history sorted chronologically.
</td>
</tr><tr>
<td>
`model`<a id="model"></a>
</td>
<td>
The model name.
</td>
</tr><tr>
<td>
`context`<a id="context"></a>
</td>
<td>
Text that should be provided to the model first, to ground the response.
</td>
</tr><tr>
<td>
`examples`<a id="examples"></a>
</td>
<td>
Examples of what the model should generate.
</td>
</tr><tr>
<td>
`temperature`<a id="temperature"></a>
</td>
<td>
Controls the randomness of the output. Must be positive.
</td>
</tr><tr>
<td>
`candidate_count`<a id="candidate_count"></a>
</td>
<td>
The **maximum** number of generated response messages to return.
</td>
</tr><tr>
<td>
`top_k`<a id="top_k"></a>
</td>
<td>
The maximum number of tokens to consider when sampling.
</td>
</tr><tr>
<td>
`top_p`<a id="top_p"></a>
</td>
<td>
The maximum cumulative probability of tokens to consider when sampling.
</td>
</tr><tr>
<td>
`last`<a id="last"></a>
</td>
<td>
A settable property that provides simple access to the last response string


A shortcut for `response.messages[0]['content']`.
</td>
</tr>
</table>



## Methods

<h3 id="reply"><code>reply</code></h3>

<a target="_blank" class="external" href="https://github.com/google/generative-ai-python/blob/master/google/generativeai/types/discuss_types.py#L199-L202">View source</a>

<pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link">
<code>@abc.abstractmethod</code>
<code>reply(
    message: <a href="../../../google/generativeai/types/MessageOptions.md"><code>google.generativeai.types.MessageOptions</code></a>
) -> 'ChatResponse'
</code></pre>

Add a message to the conversation, and get the model's response.


<h3 id="to_dict"><code>to_dict</code></h3>

<a target="_blank" class="external" href="https://github.com/google/generative-ai-python/blob/master/google/generativeai/types/discuss_types.py#L185-L197">View source</a>

<pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link">
<code>to_dict() -> Dict[str, Any]
</code></pre>




<h3 id="__eq__"><code>__eq__</code></h3>

<pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link">
<code>__eq__(
    other
)
</code></pre>

Return self==value.






<!-- Tabular view -->
 <table class="responsive fixed orange">
<colgroup><col width="214px"><col></colgroup>
<tr><th colspan="2"><h2 class="add-link">Class Variables</h2></th></tr>

<tr>
<td>
top_k<a id="top_k"></a>
</td>
<td>
`None`
</td>
</tr><tr>
<td>
top_p<a id="top_p"></a>
</td>
<td>
`None`
</td>
</tr>
</table>

